{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SoftmaxClassifier.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPgEMMRz1sY6QHh7IIMCecW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raiakash203/Machine-Learning/blob/Dimension-Reduction/SoftmaxClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ln7WY2NloUuL",
        "colab_type": "text"
      },
      "source": [
        "Basic Softmax classifier on mnist data using tensorflow.\n",
        "Implementation followed from AppliedAI course"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LicmcHkPhhus",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==1.14"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKT1oehDo0p9",
        "colab_type": "text"
      },
      "source": [
        "## SoftMaxClassfier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbhThnaf_lxl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "mnist=input_data.read_data_sets(\"MNIST\", one_hot=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxV8NkgYAMix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCpfDKbXnC8F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVCz5kUQoHyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "train_images = train_images.reshape(-1,784)\n",
        "test_images = test_images.reshape(-1,784)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ok6LUaiuoUAK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "#For one hot encoding of the data\n",
        "encoding_shape_train = (train_labels.size,train_labels.max()+1)\n",
        "encoding_shape_test = (test_labels.size,test_labels.max()+1)\n",
        "\n",
        "train_one_hot = np.zeros(encoding_shape_train)\n",
        "test_one_hot = np.zeros(encoding_shape_test)\n",
        "\n",
        "rows = np.arange(train_labels.size)\n",
        "train_one_hot[rows,train_labels] = 1\n",
        "rows = np.arange(test_labels.size)\n",
        "test_one_hot[rows,test_labels] = 1\n",
        "\n",
        "train_labels = train_one_hot\n",
        "test_labels = test_one_hot\n",
        "\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2CUle-Gohi-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"The number of data points in train \",mnist.train.images.shape[0],\"No of pixels: \",mnist.train.images.shape[-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6ClAfCKyQAQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"The number of data points in test \",mnist.test.images.shape[0],\"shape of labels: \",mnist.test.labels.shape[-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLHJaiB_zYeZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The below gives the list of GPUs and CPUs devices\n",
        "\n",
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmLz56GP5oEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItD6jsTwzfJe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X is a placeholder, as the name suggests it holds a space in the memory\n",
        "X = tf.placeholder(tf.float32,[None,784])\n",
        "\n",
        "# Varibales are same as that in any programing language\n",
        "W = tf.Variable(tf.zeros([784,10]))\n",
        "b = tf.Variable(tf.zeros([10]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkhD8dVV0YqI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The predicted values is denoted by y\n",
        "y = tf.nn.softmax(tf.matmul(X,W)+b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXk1A2p77YI-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#y_ is the true label\n",
        "y_ = tf.placeholder(tf.float32,[None,10])\n",
        "\n",
        "#The error is given by cross_entropy\n",
        "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_* tf.log(y), reduction_indices=[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMgJr2ul-Og3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The train step to minimize the loss which is cross entropy in our case\n",
        "\n",
        "train_step = tf.train.GradientDescentOptimizer(0.05).minimize(cross_entropy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzOs7BEC-0Fm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Now launch a the model in a session\n",
        "session = tf.InteractiveSession()\n",
        "\n",
        "#Now we will initialize the variables we have created\n",
        "tf.global_variables_initializer().run()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nqc0NAI2_KXj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#With each step of the loop will have a minibatch of 100 random data pointsfrom training sets\n",
        "\n",
        "for _ in range(1000):\n",
        "  batch_xs,batch_ys = mnist.train.next_batch(100)\n",
        "  session.run(train_step,feed_dict={X:batch_xs,y_:batch_ys})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXsvb6uYBJN3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xX8z7PLgNGub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "print(session.run(accuracy,feed_dict = {X:mnist.test.images,y_:mnist.test.labels}))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjZ_ZLpiOOdW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "\n",
        "def plot_dynamics(x,y,y_1,ax,colors=['b']):\n",
        "  ax.plot(x,y,'b',label='Train Loss')\n",
        "  ax.plot(x,y_1,'r',label='Test Loss')\n",
        "  if len(x)==1:\n",
        "    plt.legend()\n",
        "  fig.canvas.draw()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqY8K34nPNKM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Sumarizing everything into a single cell\n",
        "train_epooch = 20\n",
        "batch_size = 1200\n",
        "\n",
        "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = y, labels=y_))\n",
        "train_step = tf.train.GradientDescentOptimizer(0.02).minimize(cross_entropy)\n",
        "\n",
        "fig,ax = plt.subplots(1,1)\n",
        "ax.set_xlabel('epoochs')\n",
        "ax.set_ylabel('Softmax cross entropy loss')\n",
        "\n",
        "xs,ytrs,ytes = [],[],[]\n",
        "\n",
        "for epooch in range(train_epooch):\n",
        "  train_avg_er = 0 \n",
        "  test_avg_er =  0\n",
        "  total_batch = int(mnist.train.num_examples/batch_size)\n",
        "  #Loop over all batches\n",
        "  for i in range(total_batch):\n",
        "    batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
        "    _,c = session.run([train_step,cross_entropy], feed_dict = {X:batch_xs , y_:batch_ys})\n",
        "    train_avg_er += c/total_batch\n",
        "    c = session.run(cross_entropy, feed_dict = {X:mnist.test.images, y_:mnist.test.labels})\n",
        "    test_avg_er += c/total_batch\n",
        "  xs.append(epooch)\n",
        "  ytrs.append(train_avg_er)\n",
        "  ytes.append(test_avg_er)\n",
        "  plot_dynamics(xs,ytrs,ytes,ax)\n",
        "\n",
        "plot_dynamics(xs,ytrs,ytes,ax)\n",
        "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
        "print(\"Accuracy: \", accuracy.eval({X:mnist.test.images,y_:mnist.test.labels}))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4iWyswynjPf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}